{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes and organizes quote and author information of the *quotes to scrape* website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pickle\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classes and functions\n",
    "## Create the quote class\n",
    "class quote:\n",
    "    def __init__(self, text, author_name, tags, link, author=None):\n",
    "        self.text=text\n",
    "        self.author_name=author_name\n",
    "        self.tags=tags\n",
    "        self.author_link=\"http://quotes.toscrape.com\"+link\n",
    "    def round_1(self):\n",
    "        print(self.text)\n",
    "        ans=input(\"Who said this? Please input name:\\n\")\n",
    "        if ans==self.author_name:\n",
    "            print(\"Congratulations! You are correct!\")\n",
    "        else:\n",
    "            return self.round_2()\n",
    "    def round_2(self):\n",
    "        print(f\"Your answer is not correct. Please see the additional information:\\nThe person is born on {self.author.birthday}.\")\n",
    "        ans=input(\"Who said this? Please input name:\\n\")\n",
    "        if ans==self.author_name:\n",
    "            print(\"Congratulations! You are correct!\")\n",
    "        else:\n",
    "            return self.round_3()\n",
    "    def round_3(self):\n",
    "        print(f\"Your answer is not correct. Please see the additional information:\\nThe person is born in {self.author.location}.\")\n",
    "        ans=input(\"Who said this? Please input name:\\n\")\n",
    "        if ans==self.author_name:\n",
    "            print(\"Congratulations! You are correct!\")\n",
    "        else:\n",
    "            return self.round_4()\n",
    "    def round_4(self):\n",
    "        quotes_copy=quotes[:]\n",
    "        quotes_copy.remove(self)\n",
    "        sample=random.choices(quotes_copy, k=3)\n",
    "        sample_names=[quote.author_name for quote in sample]\n",
    "        sample_names.append(self.author_name)\n",
    "        sample_names.sort()\n",
    "        options_letter=[\"A\", \"B\", \"C\", \"D\"]\n",
    "        options = {options_letter[i]: sample_names[i] for i in range(len(sample_names))} \n",
    "        print(f\"Your answer is not correct. Please choose one among the four alternatives: {options}\")\n",
    "        ans=input(\"Who said this? Please input A, B, C or D:\\n\")\n",
    "        while ans not in options_letter:\n",
    "            ans=input(\"please input a letter, A, B, C or D:\\n\")\n",
    "        if options[ans]==self.author_name:\n",
    "            print(\"Congratulations! You are correct!\")\n",
    "        else:\n",
    "            print(\"You failed!\")\n",
    "        \n",
    "## Create the author_info class\n",
    "class author_info:\n",
    "    def __init__(self, name, birthday, location, info):\n",
    "        self.name=name\n",
    "        self.birthday=birthday\n",
    "        self.location=location\n",
    "        self.info=info\n",
    "## Create functions\n",
    "def author_info_get(link):\n",
    "        raw=requests.get(link)\n",
    "        return BeautifulSoup(raw.text)\n",
    "    \n",
    "def next_page(page_url):\n",
    "            link=BeautifulSoup(requests.get(page_url).text).find_all(class_=\"next\")[0].find_all(attrs={\"href\": True})[0][\"href\"]\n",
    "            return \"http://quotes.toscrape.com\"+link\n",
    "        \n",
    "def quote_combiner(initial_page_url):\n",
    "    page_url=initial_page_url\n",
    "    quotes=BeautifulSoup(requests.get(initial_page_url).text).find_all(class_=\"quote\")\n",
    "    while True:\n",
    "        try:\n",
    "            page_url=next_page(page_url)\n",
    "            quotes=quotes+BeautifulSoup(requests.get(page_url).text).find_all(class_=\"quote\")\n",
    "        except IndexError:\n",
    "            return quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the whole website\n",
    "quotes_list=quote_combiner(\"http://quotes.toscrape.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of quote class\n",
    "quotes=[quote(text=quotes_list[i].find(class_=\"text\").get_text()[1:][:-1], \n",
    "                    author_name=quotes_list[i].find(class_=\"author\").get_text(), \n",
    "                    tags=[tag.get_text() for tag in quotes_list[i].find_all(class_=\"tag\")], \n",
    "                    link=quotes_list[i].find(\"a\")[\"href\"]) \n",
    "              for i in range(len(quotes_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape author info pages\n",
    "author_info_raw=[author_info_get(quote.author_link) for quote in quotes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates instance of author_info class\n",
    "author_info_class=[\n",
    "    author_info(name=page.find(class_=\"author-title\").get_text().replace('\\n', '').strip(), \n",
    "               birthday=page.find(class_=\"author-born-date\").get_text(), \n",
    "               location=page.find(class_=\"author-born-location\").get_text()[3:], \n",
    "               info=page.find(class_=\"author-description\").get_text().replace('\\n', '').strip().split(\"More: \", 1)[0]) \n",
    "    for page in author_info_raw]\n",
    "#Add back author information back to the quotes\n",
    "for i in range(len(quotes)):\n",
    "    quotes[i].author=author_info_class[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all scraped data \n",
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump([quotes, author_info_class], f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
